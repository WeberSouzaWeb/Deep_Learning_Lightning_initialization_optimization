{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd786594",
   "metadata": {},
   "source": [
    "# <font color='blue'>Weber Souza</font>\n",
    "# <font color='blue'>Deep Learning Para Aplicações de IA com PyTorch e Lightning</font>\n",
    "\n",
    "## <font color='blue'>Estudo de Caso 2</font>\n",
    "## <font color='blue'>Os Efeitos dos Processos de Inicialização e Otimização</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48833149",
   "metadata": {},
   "source": [
    "![title](imagens/EC2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcffbb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.11.7\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c96c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# !pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "# !pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9223903d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.13.0 (from versions: 2.2.0, 2.2.1, 2.2.2)\n",
      "ERROR: No matching distribution found for torch==1.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04763438",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchvision==0.14.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6cc96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib\n",
    "import gc\n",
    "import types\n",
    "import pkg_resources\n",
    "import pytorch_lightning as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9578f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Weber Souza\n",
      "\n",
      "numpy            : 1.26.4\n",
      "torchvision      : 0.17.1\n",
      "matplotlib       : 3.8.0\n",
      "pytorch_lightning: 2.2.1\n",
      "torch            : 2.2.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Weber Souza\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0eae1",
   "metadata": {},
   "source": [
    "## Verificando o Ambiente de Desenvolvimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36956de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------Visão Geral do Ambiente---------------------------------------\n",
      "\n",
      "Device: cpu\n",
      "Pasta de Dados:  dados\n",
      "Versões dos Pacotes Requeridos:  [('matplotlib', '3.8.0'), ('numpy', '1.26.4'), ('torch', '2.2.1'), ('torchvision', '0.17.1')]\n",
      "Dispositivo Que Será Usado Para Treinar o Modelo:  cpu\n",
      "CUDA Está Disponível?  False\n",
      "Versão do PyTorch:  2.2.1+cpu\n",
      "Versão do Lightning:  2.2.1\n",
      "\n",
      "------------------Se NVIDIA-SMI não for encontrado, então CUDA não está disponível------------------\n",
      "\n",
      "Mon Apr  1 18:06:20 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.33                 Driver Version: 546.33       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce 940MX         WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A    0C    P0              N/A / 200W |      0MiB /  4096MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n",
      "Limpando a Memória da GPU (se disponível):  None\n",
      "\n",
      "------------------------------------------Fim da Checagem-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Relatório completo\n",
    "\n",
    "# Verificando o dispositivo\n",
    "processing_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Verificando se GPU pode ser usada (isso depende da plataforma CUDA estar instalada)\n",
    "torch_aval = torch.cuda.is_available()\n",
    "\n",
    "# Labels para o relatório de verificação\n",
    "lable_1 = 'Visão Geral do Ambiente'\n",
    "lable_2 = 'Se NVIDIA-SMI não for encontrado, então CUDA não está disponível'\n",
    "lable_3 = 'Fim da Checagem'\n",
    "\n",
    "# Função para verificar o que está importado nesta sessão\n",
    "def get_imports():\n",
    "\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):            \n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        poorly_named_packages = {\"PIL\": \"Pillow\", \"sklearn\": \"scikit-learn\"}\n",
    "\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "\n",
    "# Imports nesta sessão\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# Loop para verificar os requerimentos\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "        \n",
    "# Pasta com os dados (quando necessário)\n",
    "pasta_dados = r'dados'\n",
    "\n",
    "print(f'{lable_1:-^100}')\n",
    "print()\n",
    "print(f\"Device:\", processing_device)\n",
    "print(f\"Pasta de Dados: \", pasta_dados)\n",
    "print(f\"Versões dos Pacotes Requeridos: \", requirements)\n",
    "print(f\"Dispositivo Que Será Usado Para Treinar o Modelo: \", processing_device)\n",
    "print(f\"CUDA Está Disponível? \", torch_aval)\n",
    "print(\"Versão do PyTorch: \", torch.__version__)\n",
    "print(\"Versão do Lightning: \", pl.__version__)\n",
    "print()\n",
    "print(f'{lable_2:-^100}\\n')\n",
    "!nvidia-smi\n",
    "gc.collect()\n",
    "print()\n",
    "print(f\"Limpando a Memória da GPU (se disponível): \", torch.cuda.empty_cache())\n",
    "print(f'\\n{lable_3:-^100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ae39a",
   "metadata": {},
   "source": [
    "## Funções Auxiliares Para Colocar os Dados no Dispositivo de Treino (GPU ou CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615a7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter o device\n",
    "# Se disponível usamos GPU. Caso contrário usamos CPU.\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5e062bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para enviar um tensor para o device\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eabf657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para enviar os dataloaders para o device\n",
    "class DeviceDataLoader():\n",
    "\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bec935",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4aa058",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b759557",
   "metadata": {},
   "source": [
    "## Pré-Processamento dos Dados\n",
    "\n",
    "Vamos realizar as tarefas de pré-processamento dos dados (neste caso das imagens) e então carregar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f391a0",
   "metadata": {},
   "source": [
    "> Aqui nós preparamos as transformações dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas de normalização (médias e desvios para cada canal de cor)\n",
    "stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcd9129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define as Transformações \n",
    "transforms = transforms.Compose([transforms.RandomCrop(64, padding = 4, padding_mode = 'reflect'), \n",
    "                                 transforms.Resize(64),\n",
    "                                 transforms.RandomHorizontalFlip(), \n",
    "                                 transforms.ToTensor(), \n",
    "                                 transforms.Normalize(*stats, inplace = True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d453a",
   "metadata": {},
   "source": [
    "> Aqui nós carregamos os dados do disco e aplicamos as transformações. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d13a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino = datasets.ImageFolder(\"dados/treino\", transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_valid = datasets.ImageFolder(\"dados/val\", transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_teste = datasets.ImageFolder(\"dados/teste\", transform = transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fff249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Número Total de Imagens de Treino: {len(dados_treino)}\")\n",
    "print(f\"Número Total de Imagens de Validação: {len(dados_valid)}\")\n",
    "print(f\"Número Total de Imagens de Teste: {len(dados_teste)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6813ac7",
   "metadata": {},
   "source": [
    "> Aqui preparamos os data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec07d8b",
   "metadata": {},
   "source": [
    "https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3645df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros para os dataloaders\n",
    "batch_size = 8\n",
    "shuffle = True\n",
    "num_workers = 2\n",
    "pin_memory = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6085a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader de treino\n",
    "data_loader_treino = DataLoader(dados_treino, \n",
    "                                batch_size, \n",
    "                                shuffle = shuffle, \n",
    "                                num_workers = num_workers, \n",
    "                                pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader de validação\n",
    "data_loader_valid = DataLoader(dados_valid, \n",
    "                               batch_size, \n",
    "                               num_workers = num_workers, \n",
    "                               pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ef3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader de teste\n",
    "data_loader_teste = DataLoader(dados_teste, \n",
    "                               batch_size * 2, \n",
    "                               num_workers = num_workers, \n",
    "                               pin_memory = pin_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df269c26",
   "metadata": {},
   "source": [
    "> Aqui visualizamos uma amostra dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a863430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para \"desnormalizar\" os dados\n",
    "def denormalize(images, means, stds):\n",
    "    means = torch.tensor(means).reshape(1, 3, 1, 1)\n",
    "    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n",
    "    return images * stds + means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para imprimir um batch de dados\n",
    "def mostra_dados(dl):\n",
    "    for images, labels in dl:\n",
    "        fig, ax = plt.subplots(figsize = (12, 12))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        denorm_images = denormalize(images, *stats)\n",
    "        ax.imshow(make_grid(denorm_images[:64], nrow = 8).permute(1, 2, 0).clamp(0,1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostra_dados(data_loader_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312c447",
   "metadata": {},
   "source": [
    "## Arquitetura do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a acurácia\n",
    "def accuracy(outputs, labels):\n",
    "    \n",
    "    # Extrai o maior valor dos outputs (classe com maior probabilidade)\n",
    "    _, preds = torch.max(outputs, dim = 1)\n",
    "    \n",
    "    # Retorna a acurácia comparando as previsões com os valores reais\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc7890",
   "metadata": {},
   "source": [
    "A arquitetura de Rede Neural Convolucional (CNN - Convolutional Neural Network) é um tipo de modelo de rede neural projetado para processar dados que têm uma estrutura de grade, como imagens. A estrutura da CNN é inspirada na organização do córtex visual do cérebro humano, que tem neurônios que respondem a regiões específicas do campo visual.\n",
    "\n",
    "Uma CNN é composta por uma série de camadas, cada uma das quais executa uma operação específica na entrada de dados. As camadas típicas incluem:\n",
    "\n",
    "Camadas de convolução: Essas camadas aplicam filtros a pequenas regiões da entrada, de modo a extrair características visuais importantes, como bordas, texturas e formas.\n",
    "\n",
    "Camadas de pooling: Essas camadas reduzem o tamanho da representação da entrada, mantendo as características mais importantes. Isso ajuda a reduzir a complexidade do modelo e a aumentar a eficiência computacional.\n",
    "\n",
    "Camadas totalmente conectadas: Essas camadas são semelhantes às camadas usadas em redes neurais padrão. Eles recebem as características extraídas pelas camadas anteriores e as usam para gerar uma saída.\n",
    "\n",
    "As camadas são organizadas em uma topologia específica que é projetada para extrair características relevantes da entrada e classificar a imagem corretamente. Essa topologia pode variar dependendo da tarefa específica, como classificação de imagem, detecção de objeto, segmentação de imagem, entre outras.\n",
    "\n",
    "As CNNs são amplamente utilizadas em tarefas relacionadas a imagens, como classificação, detecção de objeto, reconhecimento facial, entre outras. Seu sucesso em muitas dessas tarefas se deve em grande parte à sua capacidade de aprender representações hierárquicas de características visuais relevantes, tornando-as muito eficientes para lidar com grandes volumes de dados de imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bed663b",
   "metadata": {},
   "source": [
    "Funções de inicialização dos pesos:\n",
    "\n",
    "https://pytorch.org/docs/stable/nn.init.html\n",
    "\n",
    "nn.init.kaiming_uniform_ é uma função de inicialização de pesos do PyTorch que implementa a técnica de inicialização He uniforme, proposta por He et al. em 2015.\n",
    "\n",
    "A inicialização He uniforme é uma técnica popular de inicialização de pesos que é usada comumente em redes neurais que usam ativações ReLU. A ideia por trás dessa técnica é que a inicialização aleatória dos pesos deve ser feita de tal maneira que a saída de cada camada tenha aproximadamente a mesma variância da entrada. Isso evita o problema de gradientes explodindo ou desaparecendo que pode ocorrer em redes neurais profundas.\n",
    "\n",
    "O argumento mode na função nn.init.kaiming_uniform_() especifica qual dos dois valores deve ser usado no denominador da equação: fan_in ou fan_out. O valor padrão para o argumento mode é fan_in, que significa que o denominador da equação será definido como o número de entradas para a camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c315390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador Base\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Método de resert dos pesos (parâmetros)\n",
    "    def reset_parameters(self):\n",
    "        self.weight = torch.empty(3, 4)\n",
    "        nn.init.kaiming_uniform_(self.weight, mode = 'fan_in', nonlinearity = 'relu')\n",
    "    \n",
    "    # Método para o passo de treino\n",
    "    def training_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Método para o passo de validação\n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        \n",
    "        # Calcula a acurácia\n",
    "        acc = accuracy(out, labels)     \n",
    "        \n",
    "        return {'erro_valid': loss.detach(), 'acc_valid': acc}\n",
    "        \n",
    "    # Método para o passo de validação ao final de uma época\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['erro_valid'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['acc_valid'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'erro_valid': epoch_loss.item(), 'acc_valid': epoch_acc.item()}\n",
    "    \n",
    "    # Método para o fim de cada época\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, erro_treino: {:.4f}, erro_valid: {:.4f}, acc_valid: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['erro_treino'], result['erro_valid'], result['acc_valid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641cb689",
   "metadata": {},
   "source": [
    "A arquitetura ResNet (Residual Network) é uma arquitetura de Rede Neural Convolucional (CNN) desenvolvida pela Microsoft Research em 2015. É uma arquitetura profunda que se destaca por suas conexões residuais, que permitem que as informações fluam diretamente das camadas de entrada para as camadas de saída, contornando as camadas intermediárias. Isso ajuda a prevenir o problema de desvanecimento de gradientes, que é comum em redes muito profundas e pode dificultar o treinamento.\n",
    "\n",
    "A ResNet consiste em várias camadas de convolução e normalização, seguidas por blocos residuais. Cada bloco residual é composto por várias camadas convolucionais e normalização, que são seguidas por um caminho residual. O caminho residual consiste em uma conexão direta da entrada do bloco à saída do bloco, o que permite que as informações fluam diretamente da entrada para a saída, sem passar por todas as camadas intermediárias.\n",
    "\n",
    "A ResNet é conhecida por sua capacidade de criar modelos muito profundos e poderosos, com um número muito grande de camadas. Por exemplo, a ResNet-152 tem 152 camadas e ainda assim pode ser treinada com sucesso em tarefas de reconhecimento de imagem.\n",
    "\n",
    "A arquitetura ResNet tem sido usada com sucesso em várias tarefas relacionadas a imagens, como classificação de imagens, detecção de objetos, segmentação de imagens, entre outras. Ela é considerada uma das arquiteturas mais influentes e eficazes em tarefas de visão computacional, tendo ganhado várias competições de reconhecimento de imagem, como o ImageNet Large Scale Visual Recognition Challenge (ILSVRC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd245fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco de convolução\n",
    "def conv_block(in_channels, out_channels, pool = False):\n",
    "    \n",
    "    # Camadas\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1), \n",
    "              nn.BatchNorm2d(out_channels), \n",
    "              nn.ReLU(inplace = True)]\n",
    "    \n",
    "    # Se pool = True, adiciona a camada de MaxPooling\n",
    "    if pool: \n",
    "        layers.append(nn.MaxPool2d(2))\n",
    "        \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura ResNet\n",
    "class ResNet(ImageClassificationBase):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        \n",
    "        # Inicializa o construtor da classe mãe\n",
    "        super().__init__()\n",
    "        \n",
    "        # Conv1\n",
    "        self.conv1 = conv_block(in_channels, 64)\n",
    "        \n",
    "        # Conv2\n",
    "        self.conv2 = conv_block(64, 128, pool = True)\n",
    "        \n",
    "        # Sequência de convs\n",
    "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
    "        \n",
    "        # Conv3\n",
    "        self.conv3 = conv_block(128, 256, pool = True)\n",
    "        \n",
    "        # Conv4\n",
    "        self.conv4 = conv_block(256, 512, pool = True)\n",
    "        \n",
    "         # Sequência de convs\n",
    "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
    "        \n",
    "        # Camada de classificação\n",
    "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1), \n",
    "                                        nn.Flatten(), \n",
    "                                        nn.Dropout(0.2),\n",
    "                                        nn.Linear(512, num_classes))\n",
    "    \n",
    "    # Método forward\n",
    "    def forward(self, xb):\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do modelo considerando 3 canais de cores nas imagens e 4 classes de saída\n",
    "modelo = to_device(ResNet(3, 4), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8afa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee8a869",
   "metadata": {},
   "source": [
    "> Enviamos os dataloaders para o device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76d5a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_treino = DeviceDataLoader(data_loader_treino, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_valid = DeviceDataLoader(data_loader_valid, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6453cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_teste = DeviceDataLoader(data_loader_teste, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a290ae9",
   "metadata": {},
   "source": [
    "## Funções Para o Loop de Treinamento\n",
    "\n",
    "Criaremos aqui 3 funções para auxiliar no treinamento do modelo. Começamos com a função de avaliação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4ae820",
   "metadata": {},
   "source": [
    "@torch.no_grad() é um decorador usado no PyTorch para desativar o rastreamento de gradientes durante uma passagem de inferência ou validação em um modelo treinado.\n",
    "\n",
    "Quando um modelo é treinado, o PyTorch mantém o rastreamento dos gradientes dos tensores para atualizar os pesos do modelo durante o processo de treinamento. No entanto, durante o processo de inferência ou validação, não precisamos atualizar os pesos do modelo e, portanto, não precisamos manter o rastreamento dos gradientes.\n",
    "\n",
    "Ao usar o decorador @torch.no_grad(), podemos desativar o rastreamento de gradientes durante a inferência ou validação de um modelo treinado, reduzindo o uso de memória e aumentando a velocidade de cálculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c190d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter a taxa de aprendizado\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de treino\n",
    "def treina_modelo(epochs, \n",
    "                  max_lr, \n",
    "                  model, \n",
    "                  train_loader, \n",
    "                  val_loader, \n",
    "                  weight_decay = 0, \n",
    "                  grad_clip = None, \n",
    "                  opt_func = torch.optim.SGD):\n",
    "    \n",
    "    # Limpa o cache da GPU\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Lista para o histórico de treino\n",
    "    history = []\n",
    "    \n",
    "    # Define o otimizador com a função opt_func\n",
    "    if opt_func == torch.optim.Adam:\n",
    "        optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay)\n",
    "    elif opt_func == torch.optim.SGD:\n",
    "        optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay, momentum = 0.9)\n",
    "    elif opt_func == torch.optim.RMSprop:\n",
    "        optimizer = opt_func(model.parameters(), max_lr, weight_decay = weight_decay, eps = 1e-9)\n",
    "    \n",
    "    # Configura o agendador de taxa de aprendizado de um ciclo\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, \n",
    "                                                max_lr, \n",
    "                                                epochs = epochs, \n",
    "                                                steps_per_epoch = len(train_loader))\n",
    "    \n",
    "    # Loop de treino\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Coloca o modelo em modo de treino\n",
    "        model.train()\n",
    "        \n",
    "        # Listas de controle\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        \n",
    "        # Loop para extrair os batches\n",
    "        for batch in train_loader:\n",
    "            \n",
    "            # Passo de treino\n",
    "            loss = model.training_step(batch)\n",
    "            \n",
    "            # Armazena o erro\n",
    "            train_losses.append(loss)\n",
    "            \n",
    "            # Backpropagation para calcular os gradientes\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping \n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "            \n",
    "            # Passo de otimização\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Zera os gradientes\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Registra e atualiza a taxa de aprendizado\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "        \n",
    "        # Validação\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['erro_treino'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e6a91",
   "metadata": {},
   "source": [
    "A função zero_grad() é um método usado no PyTorch para zerar os gradientes de um modelo antes de calcular os gradientes em uma nova passagem de treinamento. Ele é comumente usado após a atualização dos pesos do modelo no final de cada iteração de treinamento.\n",
    "\n",
    "Quando um modelo é treinado com base em uma função de custo, o objetivo é minimizar essa função ajustando os pesos do modelo através da atualização iterativa dos mesmos. Durante o processo de treinamento, o gradiente da função de custo em relação aos pesos do modelo é calculado por meio do método backward() do tensor correspondente à perda.\n",
    "\n",
    "No entanto, é importante lembrar que o PyTorch acumula os gradientes em cada iteração de treinamento, em vez de substituí-los. Isso é feito porque o PyTorch permite o uso de gradientes adicionais para computação autodiferenciada, onde o grafo de computação pode ter múltiplos pontos de entrada e saída. Então, quando precisamos zerar os gradientes acumulados de um modelo, podemos usar o método zero_grad().\n",
    "\n",
    "Ao usar zero_grad(), todos os gradientes acumulados em todas as camadas do modelo são zerados, garantindo que novos gradientes sejam calculados apenas com base na passagem atual de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e58ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos hiperparâmetros\n",
    "epochs = 5\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3252ac5",
   "metadata": {},
   "source": [
    "Gradient clipping é uma técnica de regularização comum em Deep Learning que é usada para evitar que o gradiente se torne muito grande durante o treinamento. O gradiente é a derivada da função de perda em relação aos pesos do modelo e é usado para atualizar os pesos durante o processo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc802a05",
   "metadata": {},
   "source": [
    "O hiperparâmetro weight_decay, também conhecido como regularização L2, é um parâmetro de ajuste comum em algoritmos de otimização em Deep Learning. Ele é usado para evitar o overfitting (sobreajuste) ao penalizar pesos grandes durante o treinamento.\n",
    "\n",
    "O hiperparâmetro weight_decay é adicionado à função de custo durante o treinamento, com o objetivo de reduzir a magnitude dos pesos do modelo. Ele é calculado como a norma L2 dos pesos, multiplicada por um fator de penalização lambda.\n",
    "\n",
    "O hiperparâmetro weight_decay é especialmente útil quando se lida com grandes conjuntos de dados ou modelos com muitos parâmetros. Ele ajuda a evitar que o modelo se torne excessivamente complexo e sofra de overfitting, melhorando sua capacidade de generalização."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e707aa",
   "metadata": {},
   "source": [
    "### Otimizador ADAM\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam\n",
    "\n",
    "O otimizador Adam (Adaptive Moment Estimation) é um algoritmo de otimização popular em Deep Learning que usa uma combinação de técnicas de otimização de gradiente estocástico e adaptação de taxa de aprendizado. Ele foi proposto por Diederik P. Kingma e Jimmy Lei Ba em 2015.\n",
    "\n",
    "O algoritmo Adam mantém uma média móvel exponencial dos gradientes de primeira ordem e dos gradientes de segunda ordem dos pesos do modelo. Isso ajuda a ajustar a taxa de aprendizado para cada peso individualmente, o que pode melhorar o desempenho e a convergência do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f87eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270b696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee3838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280ce790",
   "metadata": {},
   "source": [
    "### Otimizador SGD\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD\n",
    "\n",
    "O otimizador SGD (Stochastic Gradient Descent) é um algoritmo de otimização comum em Deep Learning que usa a técnica de gradiente estocástico. Ele é um dos algoritmos de otimização mais simples e mais utilizados em Deep Learning.\n",
    "\n",
    "O algoritmo SGD atualiza os pesos do modelo em pequenos incrementos ao longo do gradiente da função de custo em relação aos pesos. Ele calcula o gradiente de uma amostra aleatória dos dados de treinamento em cada iteração, em vez de usar todos os dados de treinamento. Isso torna o algoritmo mais eficiente em termos de tempo e memória, permitindo o treinamento de modelos com grandes conjuntos de dados.\n",
    "\n",
    "O algoritmo SGD ajusta a taxa de aprendizado, que é a magnitude da atualização dos pesos, de acordo com um valor fixo ou uma taxa de aprendizado adaptativa. Uma taxa de aprendizado fixa é um valor constante que é definido antes do treinamento. Já uma taxa de aprendizado adaptativa ajusta a taxa de aprendizado de acordo com a taxa de variação do gradiente em cada iteração.\n",
    "\n",
    "O hiperparâmetro momentum é um parâmetro de ajuste usado em algoritmos de otimização como SGD (Stochastic Gradient Descent) e suas variantes. Ele é usado para acelerar o treinamento, permitindo que o modelo tenha impulso na direção em que está sendo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb10766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a831843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef9126",
   "metadata": {},
   "source": [
    "### Otimizador RMSprop\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.optim.RMSprop.html#torch.optim.RMSprop\n",
    "\n",
    "O otimizador RMSprop (Root Mean Square Propagation) é um algoritmo de otimização comumente usado em Deep Learning que adapta a taxa de aprendizado para cada peso do modelo individualmente. Ele foi proposto por Geoffrey Hinton em 2012 como uma extensão do algoritmo Adagrad.\n",
    "\n",
    "O RMSprop usa uma média móvel exponencial dos gradientes quadráticos médios para ajustar a taxa de aprendizado em cada iteração. Ele também usa um fator de decaimento para descontar gradientes antigos em favor de gradientes mais recentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdcfc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143a0bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d735e1",
   "metadata": {},
   "source": [
    "## Conclusão Sobre o Otimizador:\n",
    "\n",
    "O Otimizador SGD com momentum apresentou a melhor performance. Vamos verificar mudanças na inicialização dos pesos usando SGD como otimizador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adccc8e",
   "metadata": {},
   "source": [
    "### Inicialização Glorot (Xavier)\n",
    "\n",
    "Inicialização Glorot, também conhecida como inicialização Xavier, é uma técnica popular de inicialização de pesos para redes neurais que foi proposta por Glorot e Bengio em 2010. A ideia por trás dessa técnica é que a inicialização aleatória dos pesos deve ser feita de tal maneira que a saída de cada camada tenha aproximadamente a mesma variância da entrada. Isso evita o problema de gradientes explodindo ou desaparecendo que pode ocorrer em redes neurais profundas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f89e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador Base\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Método de resert dos pesos (parâmetros)\n",
    "    def reset_parameters(self):\n",
    "        self.weight = torch.empty(3, 4)\n",
    "        nn.init.xavier_normal_(self.weight)\n",
    "    \n",
    "    # Método para o passo de treino\n",
    "    def training_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Método para o passo de validação\n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        \n",
    "        # Calcula a acurácia\n",
    "        acc = accuracy(out, labels)     \n",
    "        \n",
    "        return {'erro_valid': loss.detach(), 'acc_valid': acc}\n",
    "        \n",
    "    # Método para o passo de validação ao final de uma época\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['erro_valid'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['acc_valid'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'erro_valid': epoch_loss.item(), 'acc_valid': epoch_acc.item()}\n",
    "    \n",
    "    # Método para o fim de cada época\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, erro_treino: {:.4f}, erro_valid: {:.4f}, acc_valid: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['erro_treino'], result['erro_valid'], result['acc_valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77961ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do modelo considerando 3 canais de cores nas imagens e 4 classes de saída\n",
    "modelo = to_device(ResNet(3, 4), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625af566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac61091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d3e53",
   "metadata": {},
   "source": [
    "### Inicialização dos Pesos com Zero\n",
    "\n",
    "Normalmente é a estratégia menos efetiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba908fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador Base\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    # Método construtor\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    # Método de resert dos pesos (parâmetros)\n",
    "    def reset_parameters(self):\n",
    "        self.weight = torch.empty(3, 4)\n",
    "        nn.init.zeros_(self.weight)\n",
    "    \n",
    "    # Método para o passo de treino\n",
    "    def training_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels) \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Método para o passo de validação\n",
    "    def validation_step(self, batch):\n",
    "        \n",
    "        # Recebe um batch\n",
    "        images, labels = batch \n",
    "        \n",
    "        # Faz uma previsão\n",
    "        out = self(images)    \n",
    "        \n",
    "        # Calcula o erro\n",
    "        loss = F.cross_entropy(out, labels)   \n",
    "        \n",
    "        # Calcula a acurácia\n",
    "        acc = accuracy(out, labels)     \n",
    "        \n",
    "        return {'erro_valid': loss.detach(), 'acc_valid': acc}\n",
    "        \n",
    "    # Método para o passo de validação ao final de uma época\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['erro_valid'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['acc_valid'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()     \n",
    "        return {'erro_valid': epoch_loss.item(), 'acc_valid': epoch_acc.item()}\n",
    "    \n",
    "    # Método para o fim de cada época\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, erro_treino: {:.4f}, erro_valid: {:.4f}, acc_valid: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['erro_treino'], result['erro_valid'], result['acc_valid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o objeto do modelo considerando 3 canais de cores nas imagens e 4 classes de saída\n",
    "modelo = to_device(ResNet(3, 4), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de otimização\n",
    "opt_func = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dabda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "history = treina_modelo(epochs, \n",
    "                        max_lr, \n",
    "                        modelo, \n",
    "                        data_loader_treino, \n",
    "                        data_loader_valid, \n",
    "                        grad_clip = grad_clip, \n",
    "                        weight_decay = weight_decay, \n",
    "                        opt_func = opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20590028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação com dados de teste\n",
    "aval = [evaluate(modelo, data_loader_teste)]\n",
    "print(aval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6d138",
   "metadata": {},
   "source": [
    "## Conclusão Sobre a Inicialização de Pesos:\n",
    "\n",
    "A inicialização dos pesos teve um impacto menor na performance dos dados, mas isso nem sempre será verdade e o ideal é experimentar diferentes técnicas e comparar os resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658ebc5",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
